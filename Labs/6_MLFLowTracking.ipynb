{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e8031f5",
   "metadata": {},
   "source": [
    "Lab 6: MLFlow Tracking\n",
    "-------------\n",
    "\n",
    "| | |\n",
    "| --------- | --------------------------- |\n",
    "| Notebook  | 6_MLFlowTracking.ipynb    |\n",
    "| Builds On | none |\n",
    "| Time to complete | 60 minutes\n",
    "\n",
    "In this lab, we’ll be covering the essential basics of core MLflow functionality associated with tracking training event data.\n",
    "\n",
    "We’ll start by learning how to start a local MLflow Tracking server, how to access and view the MLflow UI, and move on to our first interactions with the Tracking server through the use of the MLflow Client.\n",
    "\n",
    "The lab content builds upon itself, culminating in successfully logging your first MLflow model.\n",
    "\n",
    "The topics in this lab cover:\n",
    "\n",
    "- Starting an MLflow Tracking Server (Optionally) and connecting to a Tracking Server\n",
    "- Exploring the MlflowClient API (briefly)\n",
    "- Understanding the Default Experiment\n",
    "- Searching for Experiments with the MLflow client API\n",
    "- Understanding the uses of tags and how to leverage them for model organization\n",
    "- Creating an Experiment that will contain our run (and our model)\n",
    "- Learning how to log metrics, parameters, and a model artifact to a run\n",
    "- Viewing our Experiment and our first run within the MLflow UI\n",
    "\n",
    "\n",
    "Using the MLflow Client API\n",
    "===========================\n",
    "\n",
    "In the previous section, we started an instance of the MLflow Tracking Server and the MLflow UI. For this stage, we’re going to be interfacing with the Tracking Server through one of the primary mechanisms that you will use when training ML models, the MlflowClient. For the duration of this lab, this client API will be your primary interface for MLflow’s tracking capabilities, enabling you to:\n",
    "\n",
    "- Initiate a new Experiment.\n",
    "- Start Runs within an Experiment.\n",
    "- Document parameters, metrics, and tags for your Runs.\n",
    "- Log artifacts linked to runs, such as models, tables, plots, and more.\n",
    "\n",
    "\n",
    "Importing Dependencies\n",
    "-----------------------\n",
    "\n",
    "In order to use the MLflowClient API, the initial step involves\n",
    "importing the necessary modules.\n",
    "\n",
    "With these modules imported, you're now prepared to configure the client\n",
    "and relay specifics about the location of your tracking server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from mlflow import MlflowClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab64328",
   "metadata": {},
   "source": [
    "Configuring the MLflow Tracking Client\n",
    "--------------------------------------\n",
    "\n",
    "By default, barring any modifications to the\n",
    "`MLFLOW_TRACKING_URI` environment\n",
    "variable, initializing the MlflowClient will designate your local\n",
    "storage as the tracking server. This means your experiments, data,\n",
    "models, and related attributes will be stored within the active\n",
    "execution directory.\n",
    "\n",
    "For the context of this guide, we'll utilize the tracking server\n",
    "initialized earlier, instead of using the client to\n",
    "log to the local file system directory.\n",
    "\n",
    "In order to connect to the tracking server that we created in the\n",
    "previous section of this lab, we'll need to use the uri that we\n",
    "assigned the server when we started it. The two components that we\n",
    "submitted as arguments to the `mlflow server` command were the `host`\n",
    "and the `port`. Combined, these form\n",
    "the `tracking_uri` argument that we\n",
    "will specify to start an instance of the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab70950",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e2d45",
   "metadata": {},
   "source": [
    "\n",
    "We now have a client interface to the tracking server that can both send\n",
    "data to and retrieve data from the tracking server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7994d24c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The Default Experiment\n",
    "-----------------------\n",
    "\n",
    "Before we get to logging anything to the Tracking Server, let's take a\n",
    "look at a key feature that exists at the outset of starting any MLflow\n",
    "Tracking Server: the Default Experiment.\n",
    "\n",
    "The Default Experiment is a placeholder that is used to encapsulate all\n",
    "run information if an explicit Experiment is not declared. While using\n",
    "MLflow, you'll be creating new experiments in order to organize\n",
    "projects, project iterations, or logically group large modeling\n",
    "activities together in a grouped hierarchical collection. However, if\n",
    "you manage to forget to create a new Experiment before using the MLflow\n",
    "tracking capabilities, the Default Experiment is a fallback for you to\n",
    "ensure that your valuable tracking data is not lost when executing a\n",
    "run.\n",
    "\n",
    "Let's see what this Default Experiment looks like by using the `mlflow.client.MlflowClient.search_experiments()` API.\n",
    "\n",
    "\n",
    "\n",
    "Searching Experiments\n",
    "----------------------\n",
    "\n",
    "The first thing that we're going to do is to view the metadata\n",
    "associated with the Experiments that are on the server. We can\n",
    "accomplish this through the use of the\n",
    "`mlflow.client.MlflowClient.search_experiments()` API. Let's issue a search query to see what the results are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d17cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_experiments = client.search_experiments()\n",
    "print(all_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946cf2c",
   "metadata": {},
   "source": [
    "\n",
    "It is worth noting that the return type of the\n",
    "`search_experiments()` API is not a\n",
    "basic collection structure. Rather, it is a list of\n",
    "`Experiment` objects. Many of the\n",
    "return values of MLflow's client APIs return objects that contain\n",
    "metadata attributes associated with the task being performed. This is an\n",
    "important aspect to remember, as it makes more complex sequences of\n",
    "actions easier to perform, which will be covered in later labs.\n",
    "\n",
    "With the returned collection, we can iterate over these objects with a\n",
    "comprehension to access the specific metadata attributes of the Default\n",
    "experiment.\n",
    "\n",
    "To get familiar with accessing elements from returned collections from\n",
    "MLflow APIs, let's extract the `name`\n",
    "and the `lifecycle_stage` from the\n",
    "`search_experiments()` query and\n",
    "extract these attributes into a dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_experiment = [\n",
    "    {\"name\": experiment.name, \"lifecycle_stage\": experiment.lifecycle_stage}\n",
    "    for experiment in all_experiments\n",
    "    if experiment.name == \"Default\"\n",
    "][0]\n",
    "\n",
    "pprint(default_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891ad27",
   "metadata": {},
   "source": [
    "In the next step, we'll create our first experiment and dive into the\n",
    "options that are available for providing metadata information that helps\n",
    "to keep track of related experiments and organize our runs within\n",
    "experiments so that we can effectively compare the results of different\n",
    "parameters for training runs.\n",
    "\n",
    "Creating Experiments\n",
    "====================\n",
    "\n",
    "In the previous section, we became familiar with the MLflow Client and\n",
    "its `search_experiments` API. \n",
    "\n",
    "Notes on Tags vs Experiments\n",
    "----------------------------\n",
    "\n",
    "While MLflow does provide a default experiment, it primarily serves as a\n",
    "'catch-all' safety net for runs initiated without a specified active\n",
    "experiment. However, it's not recommended for regular use. Instead,\n",
    "creating unique experiments for specific collections of runs offers\n",
    "numerous advantages, as we'll explore below.\n",
    "\n",
    "**Benefits of Defining Unique Experiments:**\n",
    "\n",
    "1\\. **Enhanced Organization**: Experiments allow you to group related\n",
    "runs, making it easier to track and compare them. This is especially\n",
    "helpful when managing numerous runs, as in large-scale projects.\n",
    "\n",
    "2\\. **Metadata Annotation**: Experiments can carry metadata that aids in\n",
    "organizing and associating runs with larger projects.\n",
    "\n",
    "Consider the scenario below: we're simulating participation in a large\n",
    "demand forecasting project. This project involves building forecasting\n",
    "models for various departments in a chain of grocery stores, each\n",
    "housing numerous products. Our focus here is the 'produce' department,\n",
    "which has several distinct items, each requiring its own forecast model.\n",
    "Organizing these models becomes paramount to ensure easy navigation and\n",
    "comparison.\n",
    "\n",
    "**When Should You Define an Experiment?**\n",
    "\n",
    "The guiding principle for creating an experiment is the consistency of\n",
    "the input data. If multiple runs use the same input dataset (even if\n",
    "they utilize different portions of it), they logically belong to the\n",
    "same experiment. For other hierarchical categorizations, using tags is\n",
    "advisable.\n",
    "\n",
    "In the example above, we could create an experiment, creating several tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198a381",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_description = (\n",
    "    \"This is the grocery forecasting project. \"\n",
    "    \"This experiment contains the produce models for apples.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"grocery-forecasting\",\n",
    "    \"store_dept\": \"produce\",\n",
    "    \"team\": \"stores-ml\",\n",
    "    \"project_quarter\": \"Q3-2023\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "produce_apples_experiment = client.create_experiment(name=\"Apple_Models\", tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4a2b9c",
   "metadata": {},
   "source": [
    "In the next section, we'll take a look at what these tags can be used\n",
    "for, which are visible in the UI, and how we can leverage the power of\n",
    "`tags` to simplify access to\n",
    "experiments that are part of a larger project.\n",
    "\n",
    "\n",
    "\n",
    "Searching Experiments\n",
    "=====================\n",
    "\n",
    "\n",
    "In the last section, we created our first MLflow Experiment, providing\n",
    "custom tags so that we can find co-related Experiments that are part of\n",
    "a larger project.\n",
    "\n",
    "In this brief section, we're going to see how to perform those searches\n",
    "with the MLflow Client API.\n",
    "\n",
    "Before we perform the search, let's take a look at our\n",
    "`Apple_Models` experiment in the UI.\n",
    "\n",
    "\n",
    "Seeing our new Experiment in the UI\n",
    "--------------------------------------\n",
    "\n",
    "As before, we're going to connect to our running MLflow Tracking server\n",
    "to view the MLflow UI. If you've closed the browser window that was\n",
    "running it, simply navigate to `http://127.0.0.1:5000` in a new browser window.\n",
    "\n",
    "### Important components to be aware of in the UI\n",
    "\n",
    "There are some important elements in the UI to be aware of at this\n",
    "point, before we start adding more exciting things like runs to our new\n",
    "experiment. Note the annotated elements on the figure below. It will be\n",
    "useful to know that these bits of data are there later on.\n",
    "\n",
    "\n",
    "[![Important Data on the Experiment View\n",
    "Page](./images//experiment-page-elements.svg)](./images//experiment-page-elements.svg)\n",
    "\n",
    "\n",
    "\n",
    "Searching based on tags\n",
    "------------------------\n",
    "\n",
    "Now that we've seen the experiment and understand which of the tags that\n",
    "we specified during the creation of the experiment are visible within\n",
    "the UI and which are not, we're going to explore the reason for defining\n",
    "those tags as we apply searches against the tracking server to find\n",
    "experiments whose custom tags values match our query terms.\n",
    "\n",
    "One of the more versatile uses of setting `tags` within Experiments is to enable searching for related\n",
    "Experiments based on a common tag. The filtering capabilities within the\n",
    "`search_experiments` API can be seen\n",
    "below, where we are searching for experiments whose custom\n",
    "`project_name` tag exactly matches\n",
    "`grocery-forecasting`.\n",
    "\n",
    "Note that the format that is used for the search filtering has some\n",
    "nuance to it. For named entities (for instance, here, the\n",
    "`tags` term in the beginning of the\n",
    "filter string), keys can be directly used. However, to reference custom\n",
    "tags, note the particular syntax used. The custom tag names are wrapped\n",
    "with back ticks (\\`) and our matching search condition is wrapped in\n",
    "single quotes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315da2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use search_experiments() to search on the project_name tag key\n",
    "\n",
    "apples_experiment = client.search_experiments(\n",
    "    filter_string=\"tags.`project_name` = 'grocery-forecasting'\"\n",
    ")\n",
    "\n",
    "pprint(apples_experiment[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e82e0e",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "The returned results above are formatted for legibility. This return\n",
    "type is an `Experiment` object, not a `dict`.\n",
    "\n",
    "In the next section, we'll begin to use this experiment to log training\n",
    "data to runs that are associated with this experiment, introducing\n",
    "another aspect of both the MLflow APIs (the fluent API) and another part\n",
    "of the MLflow UI (the run information page).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387211e9",
   "metadata": {},
   "source": [
    "Create a dataset about apples\n",
    "=============================\n",
    "\n",
    "In order to produce some meaningful data (and a model) for us to log to\n",
    "MLflow, we'll need a dataset. In the interests of sticking with our\n",
    "theme of modeling demand for produce sales, this data will actually need\n",
    "to be about apples.\n",
    "\n",
    "There's a distinctly miniscule probability of finding an actual dataset\n",
    "on the internet about this, so we can just roll up our sleeves and make\n",
    "our own.\n",
    "\n",
    "\n",
    "Defining a dataset generator\n",
    "-----------------------------\n",
    "\n",
    "For our examples to work, we're going to need something that can\n",
    "actually fit, but not something that fits too well. We're going to be\n",
    "training multiple iterations in order to show the effect of modifying\n",
    "our model's hyperparameters, so there needs to be some amount of\n",
    "unexplained variance in the feature set. However, we need some degree of\n",
    "correlation between our target variable (`demand`, in the case of our apples sales data that we want to\n",
    "predict) and the feature set.\n",
    "\n",
    "We can introduce this correlation by crafting a relationship between our\n",
    "features and our target. The random elements of some of the factors will\n",
    "handle the unexplained variance portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbcd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generate_apple_sales_data_with_promo_adjustment(base_demand: int = 1000, n_rows: int = 5000):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset for predicting apple sales demand with seasonality and inflation.\n",
    "\n",
    "    This function creates a pandas DataFrame with features relevant to apple sales.\n",
    "    The features include date, average_temperature, rainfall, weekend flag, holiday flag,\n",
    "    promotional flag, price_per_kg, and the previous day's demand. The target variable,\n",
    "    'demand', is generated based on a combination of these features with some added noise.\n",
    "\n",
    "    Args:\n",
    "        base_demand (int, optional): Base demand for apples. Defaults to 1000.\n",
    "        n_rows (int, optional): Number of rows (days) of data to generate. Defaults to 5000.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with features and target variable for apple sales prediction.\n",
    "\n",
    "    Example:\n",
    "        >>> df = generate_apple_sales_data_with_seasonality(base_demand=1200, n_rows=6000)\n",
    "        >>> df.head()\n",
    "    \"\"\"\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    np.random.seed(1234)\n",
    "\n",
    "    # Create date range\n",
    "    dates = [datetime.now() - timedelta(days=i) for i in range(n_rows)]\n",
    "    dates.reverse()\n",
    "\n",
    "    # Generate features\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"date\": dates,\n",
    "            \"average_temperature\": np.random.uniform(10, 35, n_rows),\n",
    "            \"rainfall\": np.random.exponential(5, n_rows),\n",
    "            \"weekend\": [(date.weekday() >= 5) * 1 for date in dates],\n",
    "            \"holiday\": np.random.choice([0, 1], n_rows, p=[0.97, 0.03]),\n",
    "            \"price_per_kg\": np.random.uniform(0.5, 3, n_rows),\n",
    "            \"month\": [date.month for date in dates],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Introduce inflation over time (years)\n",
    "    df[\"inflation_multiplier\"] = 1 + (df[\"date\"].dt.year - df[\"date\"].dt.year.min()) * 0.03\n",
    "\n",
    "    # Incorporate seasonality due to apple harvests\n",
    "    df[\"harvest_effect\"] = np.sin(2 * np.pi * (df[\"month\"] - 3) / 12) + np.sin(\n",
    "        2 * np.pi * (df[\"month\"] - 9) / 12\n",
    "    )\n",
    "\n",
    "    # Modify the price_per_kg based on harvest effect\n",
    "    df[\"price_per_kg\"] = df[\"price_per_kg\"] - df[\"harvest_effect\"] * 0.5\n",
    "\n",
    "    # Adjust promo periods to coincide with periods lagging peak harvest by 1 month\n",
    "    peak_months = [4, 10]  # months following the peak availability\n",
    "    df[\"promo\"] = np.where(\n",
    "        df[\"month\"].isin(peak_months),\n",
    "        1,\n",
    "        np.random.choice([0, 1], n_rows, p=[0.85, 0.15]),\n",
    "    )\n",
    "\n",
    "    # Generate target variable based on features\n",
    "    base_price_effect = -df[\"price_per_kg\"] * 50\n",
    "    seasonality_effect = df[\"harvest_effect\"] * 50\n",
    "    promo_effect = df[\"promo\"] * 200\n",
    "\n",
    "    df[\"demand\"] = (\n",
    "        base_demand\n",
    "        + base_price_effect\n",
    "        + seasonality_effect\n",
    "        + promo_effect\n",
    "        + df[\"weekend\"] * 300\n",
    "        + np.random.normal(0, 50, n_rows)\n",
    "    ) * df[\"inflation_multiplier\"]  # adding random noise\n",
    "\n",
    "    # Add previous day's demand\n",
    "    df[\"previous_days_demand\"] = df[\"demand\"].shift(1)\n",
    "    df[\"previous_days_demand\"].fillna(method=\"bfill\", inplace=True)  # fill the first row\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df.drop(columns=[\"inflation_multiplier\", \"harvest_effect\", \"month\"], inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281c676",
   "metadata": {},
   "source": [
    "Now, let's generate a dataset that we can use to train our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ed404",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_apple_sales_data_with_promo_adjustment(base_demand=1_000, n_rows=1_000)\n",
    "\n",
    "data[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4027f8",
   "metadata": {},
   "source": [
    "\n",
    "Logging our first runs with MLflow\n",
    "==================================\n",
    "\n",
    "In our previous segments, we worked through setting up our first MLflow\n",
    "Experiment and equipped it with custom tags. These tags, as we'll soon\n",
    "discover, are instrumental in seamlessly retrieving related experiments\n",
    "that belong to a broader project.\n",
    "\n",
    "In the last section, we created a dataset that we'll be using to train a\n",
    "series of models.\n",
    "\n",
    "As we advance in this section, we'll delve deeper into the core features\n",
    "of MLflow Tracking:\n",
    "\n",
    "- Making use of the `start_run` context for creating and efficiently managing runs.\n",
    "- An introduction to logging, covering tags, parameters, and metrics.\n",
    "- Understanding the role and formation of a model signature.\n",
    "- Logging a trained model, solidifying its presence in our MLflow run.\n",
    "\n",
    "But first, a foundational step awaits us. For our upcoming tasks, we\n",
    "need a dataset, specifically focused on apple sales. While it's tempting\n",
    "to scour the internet for one, crafting our own dataset will ensure it\n",
    "aligns perfectly with our objectives.\n",
    "\n",
    "\n",
    "Crafting the Apple Sales Dataset\n",
    "--------------------------------\n",
    "\n",
    "Let's roll up our sleeves and construct this dataset.\n",
    "\n",
    "We need a data set that defines the dynamics of apple sales influenced\n",
    "by various factors like weekends, promotions, and fluctuating prices.\n",
    "This dataset will serve as the bedrock upon which our predictive models\n",
    "will be built and tested.\n",
    "\n",
    "Before we get to that, though, let's take a look at what we've learned\n",
    "so far and how these principles were used when crafting this data set\n",
    "for the purposes of this lab.\n",
    "\n",
    "\n",
    "### Using Experiments in early-stage project development\n",
    "\n",
    "As the diagram below shows, I tried taking a series of shortcuts. In\n",
    "order to record what I was trying, I created a new MLflow Experiment to\n",
    "record the state of what I tried. Since I was using different data sets\n",
    "and models, each subsequent modification that I was trying necessitated\n",
    "a new Experiment.\n",
    "\n",
    "\n",
    "[![Using MLflow Tracking for building this\n",
    "demo](./images//dogfood-diagram.svg)](./images//dogfood-diagram.svg)\n",
    "\n",
    "\n",
    "\n",
    "After finding a workable approach for the dataset generator, the results\n",
    "can be seen in the MLflow UI.\n",
    "\n",
    "\n",
    "[![Checking the results of the\n",
    "test](./images//dogfood.gif)](./images//dogfood.gif)\n",
    "\n",
    "\n",
    "\n",
    "Once I found something that actually worked, I cleaned everything up\n",
    "(deleted them).\n",
    "\n",
    "\n",
    "[![Tidying\n",
    "up](./images//cleanup-experiments.gif)](./images//cleanup-experiments.gif)\n",
    "\n",
    "\n",
    "Note\n",
    "\n",
    "If you're precisely following along to this lab and you delete your\n",
    "`Apple_Models` Experiment, recreate it\n",
    "before proceeding to the next step in the lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03babb28",
   "metadata": {},
   "source": [
    "Using MLflow Tracking to keep track of training\n",
    "-----------------------------------------------\n",
    "\n",
    "Now that we have our data set and have seen a little bit of how runs are\n",
    "recorded, let's dive in to using MLflow to tracking a training\n",
    "iteration.\n",
    "\n",
    "To start with, we will need to import our required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e745bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3ea44e",
   "metadata": {},
   "source": [
    "\n",
    "Notice that here we aren't importing the `MlflowClient` directly. For this portion, we're going to be\n",
    "using the `fluent` API. The fluent APIs\n",
    "use a globally referenced state of the MLflow tracking server's uri.\n",
    "This global instance allows for us to use these 'higher-level' (simpler)\n",
    "APIs to perform every action that we can otherwise do with the\n",
    "`MlflowClient`, with the addition of\n",
    "some other useful syntax (such as context handlers that we'll be using\n",
    "very shortly) to make integrating MLflow to ML workloads as simple as\n",
    "possible.\n",
    "\n",
    "In order to use the `fluent` API, we'll\n",
    "need to set the global reference to the Tracking server's address. We do\n",
    "this via the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea8d98a",
   "metadata": {},
   "source": [
    "\n",
    "Once this is set, we can define a few more constants that we're going to\n",
    "be using when logging our training events to MLflow in the form of runs.\n",
    "We'll start by defining an Experiment that will be used to log runs to.\n",
    "The parent-child relationship of Experiments to Runs and its utility\n",
    "will become very clear once we start iterating over some ideas and need\n",
    "to compare the results of our tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a4cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sets the current active experiment to the \"Apple_Models\" experiment and returns the Experiment metadata\n",
    "apple_experiment = mlflow.set_experiment(\"Apple_Models\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"apples_rf_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"rf_apples\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b784c",
   "metadata": {},
   "source": [
    "With these variables defined, we can commence with actually training a\n",
    "model.\n",
    "\n",
    "Firstly, let's look at what we're going to be running. Following the\n",
    "code display, we'll look at an annotated version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a82896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target and drop irrelevant date field and target field\n",
    "X = data.drop(columns=[\"date\", \"demand\"])\n",
    "y = data[\"demand\"]\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 4,\n",
    "    \"bootstrap\": True,\n",
    "    \"oob_score\": False,\n",
    "    \"random_state\": 888,\n",
    "}\n",
    "\n",
    "# Train the RandomForestRegressor\n",
    "rf = RandomForestRegressor(**params)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = rf.predict(X_val)\n",
    "\n",
    "# Calculate error metrics\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"mae\": mae, \"mse\": mse, \"rmse\": rmse, \"r2\": r2}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, artifact_path=artifact_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1a0bb2",
   "metadata": {},
   "source": [
    "\n",
    "To aid in visualizing how MLflow tracking API calls add in to an ML training code base, see the figure below.\n",
    "\n",
    "\n",
    "[![Explanation of MLflow integration into ML training\n",
    "code](./images//training-annotation.png)](./images//training-annotation.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
